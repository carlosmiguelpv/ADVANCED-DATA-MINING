{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import recall_score, roc_auc_score,auc,roc_curve\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_todo = []\n",
    "false_positive_rate_todo =[]\n",
    "true_positive_rate_todo = []\n",
    "resultados = []\n",
    "sc = StandardScaler()\n",
    "sm = SMOTE(random_state=0)\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "rus = RandomUnderSampler(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(classifier, X_test, y_test, model_name):\n",
    "  y_pred = classifier.predict(X_test)\n",
    "  y_pred_prob = classifier.predict_proba(X_test)\n",
    "  \n",
    "  sensibilidad = recall_score(y_test, y_pred)\n",
    "  false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_prob[:,1])\n",
    "  roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "  gini = 2 * roc_auc - 1\n",
    "  roc_auc_todo.append(roc_auc)\n",
    "  false_positive_rate_todo.append(false_positive_rate)\n",
    "  true_positive_rate_todo.append(true_positive_rate)\n",
    "  \n",
    "  return {\n",
    "      'Modelo': model_name,\n",
    "      'Sensibilidad': sensibilidad,\n",
    "      'ROC': roc_auc,\n",
    "      'GINI': gini\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelos(X_train, X_test, y_train, y_test,):\n",
    "  resultados = []\n",
    "  knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "  knn_classifier.fit(X_train, y_train)\n",
    "  resultados.append(evaluate_model(knn_classifier, X_test, y_test, \"KNN\"))\n",
    "  \n",
    "  rl_classifier = LogisticRegression(random_state=0)\n",
    "  rl_classifier.fit(X_train, y_train)\n",
    "  resultados.append(evaluate_model(rl_classifier, X_test, y_test, \"Regresion Logistic\"))\n",
    "  \n",
    "  nb_classifier = GaussianNB()\n",
    "  nb_classifier.fit(X_train, y_train)\n",
    "  resultados.append(evaluate_model(nb_classifier, X_test, y_test, \"Naive Bayes\"))\n",
    "  \n",
    "  svc_classifier = SVC(kernel='rbf',C = 10,gamma = 2,probability=True).fit(X_train, y_train)\n",
    "  y_pred = svc_classifier.predict(X_test)\n",
    "  resultados.append(evaluate_model(svc_classifier, X_test, y_test, \"SVM\"))\n",
    "  \n",
    "  rfc_classifier = RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=600).fit(X_train, y_train)\n",
    "  y_pred = rfc_classifier.predict(X_test)\n",
    "  resultados.append(evaluate_model(rfc_classifier, X_test, y_test, \"RF\"))\n",
    "  \n",
    "  gbc_classifier = GradientBoostingClassifier(max_depth=2, max_features='log2', n_estimators=300).fit(X_train, y_train)\n",
    "  y_pred = gbc_classifier.predict(X_test)\n",
    "  resultados.append(evaluate_model(gbc_classifier, X_test, y_test, \"Boosting\"))\n",
    "  return resultados\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba(X_train, X_test, y_train, y_test):\n",
    "  X_train_base = sc.fit_transform(X_train)\n",
    "  X_test_base = sc.transform(X_test)\n",
    "\n",
    "  #SMOTE\n",
    "  X_train_smote = sc.fit_transform(X_train)\n",
    "  X_test_smote = sc.transform(X_test)\n",
    "  X_train_smote, y_train_smote = sm.fit_resample(X_train_smote, y_train)\n",
    "\n",
    "  #OVER\n",
    "  X_train_oversamplig, y_train_oversampling = ros.fit_resample(X_train, y_train)\n",
    "  X_train_oversamplig = sc.fit_transform(X_train_oversamplig)\n",
    "  X_test_oversamplig = sc.transform(X_test)\n",
    "\n",
    "  #UNDER\n",
    "  X_train_undersampling, y_train_undersampling = rus.fit_resample(X_train, y_train)\n",
    "  X_train_undersampling = sc.fit_transform(X_train_undersampling)\n",
    "  X_test_undersampling = sc.transform(X_test)\n",
    "  return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\carlo\\PYTHON CODIGOS\\GITHUB\\MDA\\ADVANCED-DATA-MINING\\Clases\\Repaso.ipynb Celda 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/PYTHON%20CODIGOS/GITHUB/MDA/ADVANCED-DATA-MINING/Clases/Repaso.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#BASE\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/carlo/PYTHON%20CODIGOS/GITHUB/MDA/ADVANCED-DATA-MINING/Clases/Repaso.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train_base \u001b[39m=\u001b[39m sc\u001b[39m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/PYTHON%20CODIGOS/GITHUB/MDA/ADVANCED-DATA-MINING/Clases/Repaso.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_test_base \u001b[39m=\u001b[39m sc\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/carlo/PYTHON%20CODIGOS/GITHUB/MDA/ADVANCED-DATA-MINING/Clases/Repaso.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#SMOTE\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "#BASE\n",
    "X_train_base = sc.fit_transform(X_train)\n",
    "X_test_base = sc.transform(X_test)\n",
    "\n",
    "#SMOTE\n",
    "X_train_smote = sc.fit_transform(X_train)\n",
    "X_test_smote = sc.transform(X_test)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train_smote, y_train)\n",
    "\n",
    "#OVER\n",
    "X_train_oversamplig, y_train_oversampling = ros.fit_resample(X_train, y_train)\n",
    "X_train_oversamplig = sc.fit_transform(X_train_oversamplig)\n",
    "X_test_oversamplig = sc.transform(X_test)\n",
    "\n",
    "#UNDER\n",
    "X_train_undersampling, y_train_undersampling = rus.fit_resample(X_train, y_train)\n",
    "X_train_undersampling = sc.fit_transform(X_train_undersampling)\n",
    "X_test_undersampling = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
